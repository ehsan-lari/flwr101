{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwBviPMKxxmG6XGQxbMC0C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehsan-lari/flwr101/blob/main/flwr_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning flwr --> CIFAR-10 Dataset\n",
        "---"
      ],
      "metadata": {
        "id": "Z_dp6PRcKLjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparation"
      ],
      "metadata": {
        "id": "VgP4DDImQSsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q flwr[simulation] -q flwr-datasets[vision]"
      ],
      "metadata": {
        "id": "-Dzx24ijsNP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "QWmzQ3wu-W4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Metrics, Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedProx\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset"
      ],
      "metadata": {
        "id": "qZIxtnwd-xYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "id": "-dIeLtn2tr1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the Dataset"
      ],
      "metadata": {
        "id": "5HKpiIpCQfpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "yKQxKysTtsNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(partition_id: int):\n",
        "    fds = FederatedDataset(dataset=\"uoft-cs/cifar10\",\n",
        "                           partitioners={\"train\": NUM_CLIENTS})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    # Divide data on each node: 80% train, 20% test\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
        "        # we will use this function to dataset.with_transform(apply_transforms)\n",
        "        # The transforms object is exactly the same\n",
        "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
        "        return batch\n",
        "\n",
        "    # Create train/val for each partition and wrap it into DataLoader\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(\n",
        "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
        "    )\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloader, valloader, testloader"
      ],
      "metadata": {
        "id": "cJCDqwO2tsoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader, _, _ = load_datasets(partition_id=0)\n",
        "batch = next(iter(trainloader))\n",
        "images, labels = batch[\"img\"], batch[\"label\"]\n",
        "\n",
        "# Reshape and convert images to a NumPy array\n",
        "# matplotlib requires images with the shape (height, width, 3)\n",
        "images = images.permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "# Denormalize\n",
        "images = images / 2 + 0.5\n",
        "\n",
        "# Create a figure and a grid of subplots\n",
        "fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "# Loop over the images and plot them\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_title(trainloader.dataset.features[\"label\"].int2str([labels[i]])[0])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Show the plot\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8DDbFXs3tCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Centralized Training with PyTorch"
      ],
      "metadata": {
        "id": "fBBnp2xu5fsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "H8LY1egh5aL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "0XBcdOt456qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "trainloader, valloader, testloader = load_datasets(partition_id=0)\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "for epoch in tqdm(range(5)):\n",
        "    train(net, trainloader, 1)\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss:.2f}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss:.2f}\\n\\taccuracy {accuracy}\")"
      ],
      "metadata": {
        "id": "ollPeutR5-Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Federated Learning with Flower"
      ],
      "metadata": {
        "id": "cJZiYqsi7GzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "_wTJ2B0r7RAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "PWzxeua_7T4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(context: Context) -> Client:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data partition\n",
        "    # Read the node_config to fetch data partition associated to this node\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "\n",
        "    # Create a single Flower client representing a single organization\n",
        "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
        "    # to convert it to a subclass of `flwr.client.Client`\n",
        "    return FlowerClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "UB2opMpA7XGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")"
      ],
      "metadata": {
        "id": "0OnqGyTa7bKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    \"\"\"Construct components that set the ServerApp behaviour.\n",
        "\n",
        "    You can use the settings in `context.run_config` to parameterize the\n",
        "    construction of all elements (e.g the strategy or the number of rounds)\n",
        "    wrapped in the returned ServerAppComponents object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Configure the server for 5 rounds of training\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "v-5axmtK7cUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the resources each of your clients need\n",
        "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "# When running on GPU, assign an entire GPU for each client\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
        "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
        "    # and how to set up the `backend_config`"
      ],
      "metadata": {
        "id": "wpvPVVHb7fgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "htgSYw-z7iDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "BRab8sWq8GFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    \"\"\"Construct components that set the ServerApp behaviour.\n",
        "\n",
        "    You can use settings in `context.run_config` to parameterize the\n",
        "    construction of all elements (e.g the strategy or the number of rounds)\n",
        "    wrapped in the returned ServerAppComponents object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.5,\n",
        "        min_fit_clients=10,\n",
        "        min_evaluate_clients=5,\n",
        "        min_available_clients=10,\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        "    )\n",
        "\n",
        "    # Configure the server for 5 rounds of training\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create a new server instance with the updated FedAvg strategy\n",
        "server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "8lR6Er3x8IA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}